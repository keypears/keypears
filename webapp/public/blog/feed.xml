<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>KeyPears Blog</title>
        <link>https://keypears.com</link>
        <description>Updates and insights from the KeyPears team</description>
        <lastBuildDate>Sun, 26 Oct 2025 11:20:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <copyright>Copyright 2025 Identellica LLC</copyright>
        <atom:link href="https://keypears.com/blog/feed.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Building KeyPears with Rust: Backend Architecture and Blake3 Proof-of-Concept]]></title>
            <link>https://keypears.com/blog/2025-10-25-rust-backend-architecture</link>
            <guid isPermaLink="false">https://keypears.com/blog/2025-10-25-rust-backend-architecture</guid>
            <pubDate>Sat, 25 Oct 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager and cryptocurrency wallet. The design decisions described here represent our development approach and may evolve b...]]></description>
            <content:encoded><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager and cryptocurrency wallet. The design decisions described here represent our development approach and may evolve before our official release.</p>
<p>We're excited to share a major architectural milestone: KeyPears now has a working Rust backend with our first proof-of-concept endpoint. This marks a significant shift in our technical approach, bringing the performance, security, and cross-platform benefits of Rust to our core cryptography and API layer.</p>
<h2>Why Rust for the Backend?</h2>
<p>When we started building KeyPears, we knew cryptography and security would be central to everything we do. After evaluating different approaches, we chose to build our backend entirely in Rust for several compelling reasons:</p>
<h3>Performance</h3>
<p>Cryptographic operations—hashing, encryption, key derivation—are CPU-intensive. Rust's zero-cost abstractions and lack of garbage collection mean we can achieve performance comparable to C/C++ without sacrificing safety. For operations users will perform thousands of times (encrypting secrets, computing hashes, deriving keys), this performance matters.</p>
<h3>Memory Safety</h3>
<p>Password managers and cryptocurrency wallets are high-value targets for attackers. Rust's ownership system and borrow checker eliminate entire classes of vulnerabilities at compile time:</p>
<ul>
<li>No buffer overflows</li>
<li>No use-after-free bugs</li>
<li>No data races in concurrent code</li>
<li>No null pointer dereferences</li>
</ul>
<p>These guarantees mean our cryptographic code has fewer attack surfaces by design.</p>
<h3>Cross-Platform Consistency</h3>
<p>KeyPears needs to run everywhere: Windows, macOS, Linux, Android, and iOS. Rust compiles to native code on all these platforms with consistent behavior. The same cryptographic library (<code>rs-lib</code>) that powers our server also powers our Tauri desktop app and will eventually power our mobile apps.</p>
<p>This eliminates the "works on my machine" problem and ensures that a secret encrypted on iOS can be decrypted on Windows with identical cryptographic operations.</p>
<h3>Strong Type System</h3>
<p>Rust's type system helps us encode security invariants at compile time. For example, we can use the type system to ensure that:</p>
<ul>
<li>Encryption keys are never accidentally logged or serialized</li>
<li>Sensitive data is properly zeroed after use</li>
<li>API responses match their OpenAPI specifications exactly</li>
</ul>
<p>This compile-time verification catches bugs before they reach production.</p>
<h2>Architecture Overview</h2>
<p>Our Rust backend consists of two main packages:</p>
<h3><code>rs-lib</code>: Core Cryptography Library</h3>
<p><code>rs-lib</code> is a shared Rust library containing all our cryptographic implementations:</p>
<ul>
<li><strong>Blake3</strong>: Fast, secure hashing and key derivation</li>
<li><strong>ACB3</strong>: AES-256-CBC + Blake3-MAC for authenticated encryption</li>
<li><strong>Key derivation</strong>: Three-tier system separating authentication from encryption</li>
<li><strong>Data structures</strong>: Core types for vaults, secrets, and synchronization</li>
</ul>
<p>This library is pure Rust with no external dependencies beyond well-audited cryptography crates. It's designed to be portable and reusable across all our platforms.</p>
<h3><code>rs-node</code>: KeyPears Node (API Server)</h3>
<p><code>rs-node</code> is our API server—what we call a "KeyPears node." It uses the Axum web framework to expose REST endpoints that clients can use for cryptographic operations and vault synchronization.</p>
<p>Key features:</p>
<ul>
<li><strong>Axum framework</strong>: Modern, type-safe HTTP server from the Tokio team</li>
<li><strong>OpenAPI 3.0</strong>: Full API specification generated from Rust code using <code>utoipa</code></li>
<li><strong>Swagger UI</strong>: Interactive API documentation at <code>/api/docs</code></li>
<li><strong>Type safety</strong>: Request/response types validated at compile time</li>
</ul>
<p>The node is designed to be self-hostable. Anyone can run their own KeyPears node for full sovereignty over their data.</p>
<h2>Blake3 Proof-of-Concept</h2>
<p>Our first working endpoint is a Blake3 hashing service at <code>/api/blake3</code>. You can try it right now:</p>
<pre><code class="language-bash">curl -X POST https://keypears.com/api/blake3 \
  -H "Content-Type: application/json" \
  -d '{"data": "Hello, KeyPears!"}'
</code></pre>
<p>This returns:</p>
<pre><code class="language-json">{
  "hash": "a1b2c3d4..."
}
</code></pre>
<p>Blake3 is our hashing algorithm of choice for KeyPears. It's:</p>
<ul>
<li><strong>Fast</strong>: Significantly faster than SHA-256 or SHA-3</li>
<li><strong>Secure</strong>: 256-bit security with no known attacks</li>
<li><strong>Versatile</strong>: Works as both a hash function and a key derivation function</li>
<li><strong>Modern</strong>: Designed in 2020 with modern CPU features in mind</li>
</ul>
<p>We use Blake3 throughout KeyPears:</p>
<ul>
<li>Deriving encryption keys from passwords</li>
<li>Generating message authentication codes (MACs)</li>
<li>Computing content hashes for deduplication</li>
<li>Creating deterministic IDs</li>
</ul>
<p>This proof-of-concept demonstrates the full stack working:</p>
<ol>
<li>Rust backend (<code>rs-node</code>) receives the request</li>
<li>Rust library (<code>rs-lib</code>) performs the Blake3 hash</li>
<li>Result is serialized and returned via Axum</li>
<li>OpenAPI documentation describes the endpoint</li>
<li>Node.js webapp proxies <code>/api/*</code> requests to the Rust node</li>
</ol>
<h2>TypeScript Frontend + Rust Backend</h2>
<p>While our backend is Rust, our frontend remains TypeScript. This gives us the best of both worlds:</p>
<ul>
<li><strong>Rust</strong>: Performance and security for cryptography and core logic</li>
<li><strong>TypeScript</strong>: Rapid development and rich ecosystem for UI</li>
</ul>
<p>Our architecture uses:</p>
<ul>
<li><strong>Tauri</strong>: Native desktop apps with Rust backend + web frontend</li>
<li><strong>React Router</strong>: Type-safe routing for web and desktop apps</li>
<li><strong>shadcn</strong>: UI components with Catppuccin theme</li>
<li><strong>Type-safe API client</strong>: Generated from OpenAPI spec for compile-time safety</li>
</ul>
<p>The Tauri app embeds the same <code>rs-lib</code> cryptography that powers the KeyPears node. This means the desktop app has full offline capability—it doesn't need a server for cryptographic operations. The server is only needed for synchronization across devices.</p>
<h2>Deployment Architecture</h2>
<p>In production, we run a dual-server setup:</p>
<ol>
<li><strong>KeyPears node (Rust)</strong>: Runs on port 4274, handles API requests</li>
<li><strong>Webapp server (Node.js)</strong>: Runs on port 4273, serves the landing page and proxies API requests</li>
</ol>
<p>The Node.js server forwards all <code>/api/*</code> requests to the Rust node via <code>http-proxy-middleware</code>. This gives us:</p>
<ul>
<li>Single-domain simplicity (no CORS issues)</li>
<li>Independent scaling of API and web traffic</li>
<li>Clean separation of concerns</li>
</ul>
<p>Both services run in a single Docker container on AWS Fargate, deployed via ECS.</p>
<h2>Interactive API Documentation</h2>
<p>One of the benefits of Rust's <code>utoipa</code> library is automatic OpenAPI documentation generation. You can explore our API interactively at:</p>
<p><strong>https://keypears.com/api/docs</strong></p>
<p>This Swagger UI is generated directly from our Rust code. Every endpoint, request type, and response type is documented with examples. As we add new endpoints, the documentation updates automatically.</p>
<h2>What's Next?</h2>
<p>The Blake3 endpoint is just the beginning. We're actively building:</p>
<h3>Vault Operations</h3>
<ul>
<li>Create and encrypt vaults</li>
<li>Derive encryption keys from passwords</li>
<li>Store and retrieve encrypted secrets</li>
</ul>
<h3>Synchronization Protocol</h3>
<ul>
<li>Append-only logs for conflict-free sync</li>
<li>Server-side coordination for multi-device sync</li>
<li>End-to-end encryption (servers never see plaintext)</li>
</ul>
<h3>Diffie-Hellman Key Exchange</h3>
<ul>
<li>Peer-to-peer secret sharing across domains</li>
<li>Email-style addressing (<code>alice@example.com</code> ↔ <code>bob@example2.com</code>)</li>
<li>Public key discovery via federated nodes</li>
</ul>
<h3>Cross-Platform Clients</h3>
<ul>
<li>Desktop apps (Windows, macOS, Linux) via Tauri</li>
<li>Mobile apps (Android, iOS) - coming soon</li>
<li>Web interface for emergency access</li>
</ul>
<p>All of these features will be built on the same foundation: Rust for security-critical operations, TypeScript for user interfaces.</p>
<h2>Open Source and Self-Hostable</h2>
<p>Everything we're building is open source under Apache 2.0. You can:</p>
<ul>
<li>Review the code for security</li>
<li>Run your own KeyPears node</li>
<li>Contribute improvements</li>
<li>Build custom clients</li>
</ul>
<p>The KeyPears node is designed to be self-hostable. Our deployment documentation walks through:</p>
<ul>
<li>Cross-compiling for Linux (even from macOS)</li>
<li>Docker containerization</li>
<li>AWS Fargate deployment</li>
<li>Domain configuration and SSL</li>
</ul>
<p>We want KeyPears to be decentralized by default. Anyone should be able to run a node, just like anyone can run an email server.</p>
<h2>Conclusion</h2>
<p>Building KeyPears with Rust has been an excellent decision. The language's emphasis on safety, performance, and correctness aligns perfectly with our security requirements. The Blake3 proof-of-concept validates our architecture: Rust backend for cryptography, TypeScript frontend for user experience, and a clean API boundary between them.</p>
<p>We're excited to continue building. If you're interested in following along, check out:</p>
<ul>
<li><strong>Live demo</strong>: Try the Blake3 endpoint at https://keypears.com/api/blake3</li>
<li><strong>API docs</strong>: Explore the OpenAPI spec at https://keypears.com/api/docs</li>
<li><strong>Source code</strong>: Coming soon on GitHub</li>
</ul>
<p>We'll continue sharing our progress through these blog posts. Next up: vault encryption and key derivation in Rust.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Progress on Secret Synchronization: A Future-Proof Schema]]></title>
            <link>https://keypears.com/blog/2025-10-07-progress-on-secret-synchronization</link>
            <guid isPermaLink="false">https://keypears.com/blog/2025-10-07-progress-on-secret-synchronization</guid>
            <pubDate>Tue, 07 Oct 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager. The
design decisions described here represent our development approach and may
evolve before our official release...]]></description>
            <content:encoded><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager. The
design decisions described here represent our development approach and may
evolve before our official release.</p>
<p>We've made significant progress on KeyPears' secret synchronization
architecture. Today we're sharing how we redesigned our schema to support
diverse secret types while maintaining the small-sync-unit principle that makes
our synchronization protocol efficient and reliable.</p>
<h2>The Problem</h2>
<p>Our original schema was built around passwords. It had fields like
<code>encryptedPassword</code>, <code>username</code>, <code>domain</code>, and <code>notes</code>. This worked fine for
basic password management, but it created limitations:</p>
<ul>
<li><strong>Type inflexibility</strong>: How do you store an API key? A cryptocurrency wallet
with multiple components? Environment variables?</li>
<li><strong>No grouping</strong>: Secrets existed in isolation. There was no way to represent
"this API token belongs to this account" or "these 20 environment variables
form one .env file"</li>
<li><strong>No hierarchy</strong>: No folders, no organization beyond a flat list</li>
<li><strong>KeePass import impossible</strong>: KeePass has groups (folders) and custom fields
(additional key-value pairs per entry). We couldn't represent either.</li>
</ul>
<p>We needed a more flexible schema without abandoning our core architectural
principle: <strong>every secret must sync independently</strong> to keep network overhead
small and conflict resolution simple.</p>
<h2>The Solution: Three Changes</h2>
<p>We evolved the <code>SecretUpdate</code> schema with three key additions: multi-type
support, dual hierarchy mechanisms, and JSON-based storage.</p>
<h3>1. Multi-Type Support</h3>
<p>First, we made the schema generic enough to handle any small secret:</p>
<pre><code class="language-typescript">type: "password" | "envvar" | "apikey" | "walletkey" | "passkey"
encryptedData: string  // Previously: encryptedPassword
encryptedNotes: string // Previously: notes
</code></pre>
<p>The <code>type</code> field distinguishes what kind of secret this is. The generic
<code>encryptedData</code> field holds the actual secret value (password, API key, private
key, etc.). Password-specific fields like <code>domain</code>, <code>username</code>, and <code>email</code>
remain in the schema but are optional—used primarily when <code>type</code> is <code>password</code>.</p>
<p>This small change opens up KeyPears to handle:</p>
<ul>
<li><strong>Environment variables</strong>: Type <code>envvar</code>, name <code>DATABASE_URL</code>, encrypted value
in <code>encryptedData</code></li>
<li><strong>API keys</strong>: Type <code>apikey</code>, service name in a <code>label</code> field, key in
<code>encryptedData</code></li>
<li><strong>Wallet keys</strong>: Type <code>walletkey</code>, blockchain type in metadata, private key in
<code>encryptedData</code></li>
<li><strong>Passkeys</strong>: Type <code>passkey</code>, credential ID and public key in metadata,
private key in <code>encryptedData</code></li>
</ul>
<h3>2. Dual Hierarchy: Folders and ParentId</h3>
<p>The second change introduces two different hierarchy mechanisms, each serving a
specific purpose:</p>
<pre><code class="language-typescript">folders: string[]      // ["Work", "Projects", "Client A"]
tags: string[]         // ["production", "critical"]
parentId: string       // ULID of parent secret (max depth 1)
</code></pre>
<p><strong>Folders</strong> provide unlimited-depth organizational hierarchy. They're just an
array of strings representing the path:</p>
<pre><code class="language-typescript">folders: ["Work", "AWS", "Production"]
folders: ["Personal", "Banking"]
folders: []  // Root level
</code></pre>
<p>This maps perfectly to KeePass Groups and lets users organize thousands of
secrets into a familiar folder structure.</p>
<p><strong>Tags</strong> provide orthogonal categorization. A secret can have multiple tags for
cross-cutting concerns:</p>
<pre><code class="language-typescript">tags: ["production-env", "requires-rotation", "shared-with-team"]
</code></pre>
<p><strong>ParentId</strong> creates actual parent-child relationships between secrets. This is
where it gets interesting.</p>
<h2>ParentId: Secrets Containing Secrets</h2>
<p>The <code>parentId</code> field lets one secret "contain" other secrets. A simple example:</p>
<pre><code class="language-typescript">// Parent: The main account
{
  secretId: "abc123",
  name: "GitHub Account",
  type: "password",
  encryptedData: "&#x3C;main password>"
}

// Child: API token for the same account
{
  secretId: "def456",
  name: "API Token",
  type: "apikey",
  parentId: "abc123",
  encryptedData: "&#x3C;token>"
}
</code></pre>
<p>This models KeePass's custom fields—additional key-value pairs that belong to an
entry. In KeePass, you might have a GitHub entry with standard fields (username,
password, URL) plus custom fields for API tokens, 2FA backup codes, or recovery
emails.</p>
<p>In KeyPears, each custom field becomes its own secret with a <code>parentId</code> pointing
to the parent. Each syncs independently (small sync units!), but they're
logically grouped.</p>
<h3>The Depth Limit: Security Through Simplicity</h3>
<p>Here's the critical constraint: <strong>a secret can have a parent, but that parent
cannot have a parent</strong>. Maximum depth is 1. No grandparents allowed.</p>
<p>Why? Three reasons:</p>
<p><strong>1. Security</strong>: Client-generated IDs open an attack vector for malicious
clients creating circular references or extremely deep chains. With depth=1, the
validation is trivial:</p>
<pre><code class="language-typescript">async function validateParentChain(secretId: string, parentId?: string) {
  if (!parentId) return; // No parent, valid
  if (parentId === secretId) throw new Error("Cannot self-reference");

  const parent = await getSecretHistory(parentId);
  if (parent.length > 0 &#x26;&#x26; parent[0].parentId) {
    throw new Error("Cannot nest more than one level deep");
  }
}
</code></pre>
<p>One database lookup. No recursion. No visited sets. O(1) validation that
attackers can't exploit.</p>
<p><strong>2. Performance</strong>: Validating unlimited depth requires recursive queries.
Validating depth=1 requires one query. Simple.</p>
<p><strong>3. Sufficient for real use cases</strong>:</p>
<ul>
<li>Folder with secrets ✓</li>
<li>Entry with custom fields ✓</li>
<li>Environment variable group ✓</li>
</ul>
<p>What we lose: deeply nested folder hierarchies via <code>parentId</code>. But we have
<code>folders</code> for that! The two mechanisms complement each other perfectly.</p>
<h2>Why Two Hierarchy Systems?</h2>
<p>It might seem redundant to have both <code>folders</code> and <code>parentId</code>, but they serve
different purposes:</p>
<p><strong>Folders</strong> are for <strong>organizational hierarchy</strong>. They map to KeePass Groups.
They're pure metadata—just strings representing a path. They have unlimited
depth because they're just labels, not database relationships.</p>
<p><strong>ParentId</strong> is for <strong>data relationships</strong>. It maps to KeePass custom fields. It
creates actual parent-child relationships where one secret logically contains
others. Each child syncs independently, maintaining small sync units.</p>
<p>Together, they enable full KeePass import:</p>
<pre><code class="language-typescript">// KeePass structure:
// Work/Projects/GitHub (Group path)
//   - GitHub Account (Entry)
//     - Username: alice
//     - Password: ••••••
//     - Custom: API Token (protected)
//     - Custom: 2FA Codes (protected)

// KeyPears representation:
{
  secretId: "main",
  name: "GitHub Account",
  type: "password",
  folders: ["Work", "Projects", "GitHub"],
  username: "alice",
  encryptedData: "&#x3C;password>"
}
{
  secretId: "token",
  name: "API Token",
  type: "apikey",
  folders: ["Work", "Projects", "GitHub"], // Inherits folder
  parentId: "main",
  encryptedData: "&#x3C;token>"
}
{
  secretId: "codes",
  name: "2FA Codes",
  type: "password",
  folders: ["Work", "Projects", "GitHub"],
  parentId: "main",
  encryptedData: "&#x3C;codes>"
}
</code></pre>
<p>The folder path provides organization. The <code>parentId</code> relationships show which
secrets belong together. Each secret syncs independently.</p>
<h2>JSON-Based Storage: Migration-Proof Architecture</h2>
<p>The third major change is how we store secrets in the database. We moved to a
hybrid approach:</p>
<pre><code class="language-sql">CREATE TABLE secret_update (
  id TEXT PRIMARY KEY,
  vault_id TEXT NOT NULL,
  secret_id TEXT NOT NULL,
  name TEXT NOT NULL,
  type TEXT NOT NULL DEFAULT 'password',
  parent_id TEXT,
  created_at INTEGER NOT NULL,
  deleted INTEGER NOT NULL DEFAULT 0,

  -- Source of truth: full JSON object
  secret_update_json TEXT NOT NULL
);

CREATE INDEX idx_secret_updates_name ON secret_update(name);
CREATE INDEX idx_secret_updates_type ON secret_update(type);
CREATE INDEX idx_secret_updates_parent_id ON secret_update(parent_id);
</code></pre>
<p>Notice what's happening here. We store the <strong>entire <code>SecretUpdate</code> object</strong> as
JSON in <code>secret_update_json</code>. The other columns (<code>name</code>, <code>type</code>, <code>parent_id</code>,
etc.) are duplicates of data from the JSON, extracted for indexing.</p>
<p>The JSON is the source of truth. The columns are for performance.</p>
<h3>Why This Approach?</h3>
<p><strong>Adding fields requires no migration</strong>. Want to add a <code>label</code> field? Update the
Zod schema, start writing it to the JSON, and you're done. The database doesn't
care—it's just storing JSON.</p>
<p>When we added <code>parentId</code> to the schema, we:</p>
<ol>
<li>Updated the Zod schema in TypeScript</li>
<li>Added <code>parent_id</code> column to the database (for indexing)</li>
<li>Started serializing <code>parentId</code> to the JSON</li>
</ol>
<p>Users with existing vaults see <code>parentId: undefined</code> in their JSON. No
migration, no data transformation. Just works.</p>
<p>This architecture is <strong>future-proof</strong>. We can evolve the schema rapidly during
development without worrying about breaking existing databases.</p>
<h3>When We Ship v1.0</h3>
<p>Before our first production release, we'll generate one clean migration from the
final schema. That becomes our baseline. After that, we'll only add new
migrations—never delete old ones—because users will have the old migrations
applied.</p>
<p>But during development? We delete and regenerate migrations freely. The JSON
storage strategy makes this painless.</p>
<h2>What This Enables</h2>
<p>With these changes in place, KeyPears can now handle:</p>
<h3>KeePass Import (Future Feature)</h3>
<p>Full KeePass <code>.kdbx</code> import support, including:</p>
<ul>
<li>Nested groups → <code>folders</code> array</li>
<li>Entries → secrets with <code>type: "password"</code></li>
<li>Custom protected fields → child secrets with <code>parentId</code></li>
<li>Entry metadata → password-specific fields</li>
</ul>
<p>The only thing we won't import: file attachments. By design. We're optimizing
for small secrets that sync efficiently.</p>
<h3>Environment Variables</h3>
<p>Create a parent secret "Production Environment" and attach child secrets for
each variable:</p>
<pre><code class="language-typescript">{ name: "Production Env", type: "folder" }  // Parent
{ name: "DATABASE_URL", type: "envvar", parentId: "..." }
{ name: "API_SECRET", type: "envvar", parentId: "..." }
{ name: "STRIPE_KEY", type: "envvar", parentId: "..." }
</code></pre>
<p>Or use tags instead:</p>
<pre><code class="language-typescript">{ name: "DATABASE_URL", type: "envvar", tags: ["prod-env"] }
{ name: "API_SECRET", type: "envvar", tags: ["prod-env"] }
</code></pre>
<p>Both approaches work. <code>parentId</code> creates explicit grouping. Tags create implicit
sets.</p>
<h3>Cryptocurrency Wallets</h3>
<p>Store wallet keys with relevant metadata:</p>
<pre><code class="language-typescript">{
  name: "Ethereum Main Wallet",
  type: "walletkey",
  encryptedData: "&#x3C;private key>",
  folders: ["Crypto", "Ethereum"],
  tags: ["high-value", "cold-storage"]
}
</code></pre>
<h3>API Keys with Secrets</h3>
<p>Store API key pairs as parent-child:</p>
<pre><code class="language-typescript">{ name: "Stripe", type: "apikey", encryptedData: "&#x3C;public key>" }
{ name: "Secret Key", type: "apikey", parentId: "...", encryptedData: "&#x3C;secret>" }
</code></pre>
<h2>Synchronization Properties</h2>
<p>These changes maintain our core synchronization principles:</p>
<p><strong>Small sync units</strong>: Each secret syncs independently. A 50-entry KeePass import
becomes 50 individual secrets, each a few hundred bytes. If two users edit
different entries, no conflicts.</p>
<p><strong>Atomic updates</strong>: Each <code>SecretUpdate</code> is immutable once created. Updates
create new records in an append-only log. The latest update wins
(last-write-wins conflict resolution).</p>
<p><strong>Efficient</strong>: Only changed secrets sync. If you update one child secret, you
sync one small object, not the entire parent-child group.</p>
<p><strong>Validated</strong>: The <code>parentId</code> depth limit prevents malicious clients from
creating expensive recursive structures.</p>
<h2>Looking Ahead</h2>
<p>This schema evolution lays the groundwork for several future features:</p>
<ul>
<li><strong>UI for child secrets</strong>: Show "API Token" nested under "GitHub Account" in
the secret list</li>
<li><strong>KeePass import</strong>: Full <code>.kdbx</code> file import with groups and custom fields</li>
<li><strong>Environment variable templates</strong>: Quick creation of common .env structures</li>
<li><strong>Bulk operations</strong>: Delete/restore an entire group by operating on all
children</li>
</ul>
<p>The foundation is solid. The architecture is flexible. The sync protocol remains
simple and efficient.</p>
<p>We're building KeyPears to be more than a password manager—it's a secure,
self-custodied secret manager that handles everything from passwords to
environment variables to cryptocurrency keys. And it all syncs seamlessly across
your devices without trusting a central authority with your encryption keys.</p>
<h2>Technical Details</h2>
<p>For those interested in the implementation:</p>
<ul>
<li><strong>Schema definition</strong>: Zod validation in TypeScript, ensuring type safety</li>
<li><strong>Database</strong>: SQLite via Drizzle ORM with the sqlite-proxy adapter</li>
<li><strong>Migration</strong>: Custom migration runner that tracks applied migrations</li>
<li><strong>Validation</strong>: O(1) parent chain validation with single database lookup</li>
<li><strong>Indexes</strong>: <code>name</code>, <code>type</code>, <code>parent_id</code>, and composite
<code>vault_id + secret_id + created_at</code></li>
</ul>
<p>The code is Apache 2.0 licensed and available on GitHub. We're building in the
open, one commit at a time.</p>
<p>More updates coming soon.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[How KeyPears Protects Your Vault: Encryption and Key Derivation]]></title>
            <link>https://keypears.com/blog/2025-10-05-vault-encryption-key-derivation</link>
            <guid isPermaLink="false">https://keypears.com/blog/2025-10-05-vault-encryption-key-derivation</guid>
            <pubDate>Sun, 05 Oct 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[<p>One of the core security features of KeyPears is how we protect your vault
encryption keys. Today, we're diving deep into our three-tier key derivation
system and explaining how we ensure that even...]]></description>
            <content:encoded><![CDATA[<p>One of the core security features of KeyPears is how we protect your vault
encryption keys. Today, we're diving deep into our three-tier key derivation
system and explaining how we ensure that even if a server is compromised, your
encrypted data remains secure.</p>
<h2>The Problem: Authentication vs. Encryption</h2>
<p>Most password managers face a fundamental challenge: you need to send
<em>something</em> to the server to prove who you are, but you also need to keep your
encryption key secret so the server can't decrypt your vault. Using the same key
for both purposes creates a security vulnerability—if the server is compromised,
an attacker gains access to your encryption key.</p>
<p>KeyPears solves this by deriving two separate keys from your password: one for
logging in to the server, and one for encrypting your vault. The server only
ever sees the login key, never the encryption key.</p>
<h2>Three-Tier Key Derivation</h2>
<p>When you create a vault in KeyPears, we don't just hash your password once.
Instead, we use a three-tier key derivation system:</p>
<pre><code>Master Password
  ↓ blake3Pbkdf (100,000 rounds)
Password Key (stored encrypted with PIN on device)
  ↓
  ├→ blake3Pbkdf (100,000 rounds) → Encryption Key
  └→ blake3Pbkdf (100,000 rounds) → Login Key
</code></pre>
<h3>1. Password Key: The Root of Trust</h3>
<p>The first step derives a <strong>password key</strong> from your master password using
100,000 rounds of our Blake3-based PBKDF. This intermediate key is stored on
your device, encrypted with your PIN for quick unlock. It never leaves your
device and is never sent to any server.</p>
<p>The password key acts as the root of trust for deriving the other two keys.</p>
<h3>2. Encryption Key: Protecting Your Vault</h3>
<p>From the password key, we derive an <strong>encryption key</strong> through another 100,000
rounds of Blake3 PBKDF. This key is used for one purpose only: encrypting and
decrypting your master vault key.</p>
<p>Wait—encrypting a key with another key? Yes! Your vault itself is encrypted with
a randomly generated <strong>master vault key</strong>. This master key is immutable and
never changes. The encryption key derived from your password is used to encrypt
this master vault key before storing it in the database.</p>
<p>This architecture allows you to change your password without re-encrypting your
entire vault—we just re-encrypt the master vault key with the new encryption
key.</p>
<p>The encryption key is ephemeral. We derive it when needed, use it immediately,
and discard it. It is never persisted to disk and never sent anywhere.</p>
<h3>3. Login Key: Server Authentication</h3>
<p>The third key in our hierarchy is the <strong>login key</strong>, also derived from the
password key through 100,000 rounds of Blake3 PBKDF. This is the only key that
gets sent to the server for authentication.</p>
<p>Because the login key is derived separately from the encryption key,
compromising one doesn't compromise the other. Even if a server is breached and
the login key is stolen, the attacker cannot derive the encryption key needed to
decrypt your vault.</p>
<h2>Blake3 PBKDF: Fast and Secure</h2>
<p>You might notice we're using 100,000 rounds of Blake3 PBKDF rather than a
standard algorithm like PBKDF2. Blake3 is a modern, extremely fast cryptographic
hash function. Even at 100,000 rounds, the entire key derivation completes in
milliseconds on modern hardware.</p>
<p>Our Blake3-based PBKDF works by iteratively applying Blake3's keyed MAC mode:</p>
<pre><code>Round 1: result = blake3Mac(salt, password)
Round 2: result = blake3Mac(salt, result_from_round_1)
...
Round 100,000: result = blake3Mac(salt, result_from_round_99,999)
</code></pre>
<p>Each round adds computational cost for attackers trying to brute-force your
password, while remaining fast enough for legitimate use.</p>
<h2>Salt Derivation</h2>
<p>Each key derivation uses a different salt to ensure cryptographic separation:</p>
<ul>
<li>
<p><strong>Password Salt</strong>: Derived deterministically from your password using
<code>blake3Mac(blake3Hash("KeyPears password salt v1"), password)</code>. This ensures
the same password always produces the same password key.</p>
</li>
<li>
<p><strong>Encryption Salt</strong>: A global constant
<code>blake3Hash("KeyPears encryption salt v1")</code> used for all users. This is safe
because the encryption key is derived from the password key, not directly from
the password.</p>
</li>
<li>
<p><strong>Login Salt</strong>: Another global constant
<code>blake3Hash("KeyPears login salt v1")</code>. Again, safe because it's derived from
the password key.</p>
</li>
</ul>
<h2>Security Properties</h2>
<p>This architecture provides several important security guarantees:</p>
<h3>Defense Against Server Compromise</h3>
<p>If a KeyPears server is compromised, the attacker gains access to:</p>
<ul>
<li>Encrypted vault data</li>
<li>Login keys for authentication</li>
</ul>
<p>The attacker does NOT gain access to:</p>
<ul>
<li>Master passwords</li>
<li>Password keys</li>
<li>Encryption keys</li>
<li>Master vault keys</li>
<li>Decrypted vault contents</li>
</ul>
<p>Without the encryption key, the encrypted vault data is useless to the attacker.</p>
<h3>Defense Against Encrypted Data Theft</h3>
<p>If someone steals your encrypted vault data but doesn't have your credentials:</p>
<ul>
<li>They cannot decrypt it without the encryption key</li>
<li>The encryption key requires the password key</li>
<li>The password key requires your master password</li>
<li>100,000 rounds of Blake3 PBKDF make brute-forcing expensive</li>
</ul>
<h3>Key Separation</h3>
<p>The three keys are cryptographically isolated. Knowing the login key doesn't
help you derive the encryption key, and vice versa. Both require the password
key, which requires the master password.</p>
<h2>The Vault Key Hash: Verification</h2>
<p>When you enter your password to unlock a vault, KeyPears needs to verify you
entered it correctly. We do this by storing a Blake3 hash of the master vault
key in the database.</p>
<p>When you unlock:</p>
<ol>
<li>Derive password key from your password</li>
<li>Derive encryption key from password key</li>
<li>Decrypt the master vault key using the encryption key</li>
<li>Hash the decrypted master vault key</li>
<li>Compare with the stored hash</li>
</ol>
<p>If the hashes match, you entered the correct password. If not, the password is
wrong. This verification happens entirely on your device—the master vault key
never leaves your device, even temporarily.</p>
<h2>Putting It All Together</h2>
<p>Here's what happens when you create a new vault:</p>
<ol>
<li>You enter a master password</li>
<li>KeyPears derives a password key (100k rounds Blake3)</li>
<li>Derives an encryption key from the password key (100k rounds Blake3)</li>
<li>Generates a random master vault key</li>
<li>Encrypts the master vault key with the encryption key</li>
<li>Hashes the master vault key for verification</li>
<li>Stores the encrypted vault key and hash in your local database</li>
</ol>
<p>When you sync to a server:</p>
<ol>
<li>Derive the login key from your password key (100k rounds Blake3)</li>
<li>Send the login key to the server for authentication</li>
<li>Server returns your encrypted master vault key (and other encrypted vault
data)</li>
<li>Derive the encryption key (never sent to server)</li>
<li>Decrypt the master vault key locally</li>
<li>Use the master vault key to decrypt your secrets</li>
</ol>
<p>The server facilitates synchronization but never has the keys needed to decrypt
your data.</p>
<h2>Looking Ahead</h2>
<p>This architecture lays the foundation for secure sharing between users. In
future posts, we'll explore how KeyPears uses Diffie-Hellman key exchange to
share secrets securely between users, and how the master vault key enables
efficient re-encryption without re-deriving keys.</p>
<p>For now, the key takeaway is simple: KeyPears separates authentication from
encryption. Your server can verify who you are without ever having the ability
to decrypt your data. It's cryptography working exactly as it should.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Drizzle SQLite Database Migrations in Tauri 2.0]]></title>
            <link>https://keypears.com/blog/2025-10-04-drizzle-sqlite-tauri</link>
            <guid isPermaLink="false">https://keypears.com/blog/2025-10-04-drizzle-sqlite-tauri</guid>
            <pubDate>Sat, 04 Oct 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager. The
solutions described here are part of our development process and may evolve
before our official release.</p>
...]]></description>
            <content:encoded><![CDATA[<p><strong>Note:</strong> KeyPears is a work-in-progress open-source password manager. The
solutions described here are part of our development process and may evolve
before our official release.</p>
<h2>The Problem</h2>
<p>Building a local-first application with Tauri 2.0, we needed a robust database
solution for storing encrypted vault data on users' devices. We wanted:</p>
<ul>
<li>Type-safe database queries</li>
<li>Proper schema migrations that work in production</li>
<li>Pure TypeScript implementation (no Rust for basic DB operations)</li>
<li>A solution that works across desktop and mobile platforms</li>
</ul>
<p>After evaluating options, we chose <strong>Drizzle ORM</strong> with <strong>SQLite</strong> via the
official <strong>tauri-plugin-sql</strong>. This combination gives us TypeScript-first
development with the reliability of SQLite.</p>
<h2>The Challenge</h2>
<p>Unlike traditional Node.js environments where you have direct filesystem access
and can use drivers like <code>better-sqlite3</code>, Tauri's sandboxed environment
requires a different approach. Drizzle's standard migration tools assume direct
database access, but with Tauri, we need to go through the plugin system.</p>
<p>Here's how we solved it.</p>
<h2>Tech Stack</h2>
<ul>
<li><strong>Tauri 2.0</strong> - Cross-platform app framework</li>
<li><strong>Drizzle ORM</strong> - TypeScript ORM</li>
<li><strong>drizzle-kit</strong> - Schema migration generator</li>
<li><strong>@tauri-apps/plugin-sql</strong> - Official Tauri SQLite plugin</li>
<li><strong>React Router</strong> - For app routing and loaders</li>
</ul>
<h2>Step 1: Install Dependencies</h2>
<p>First, add the necessary packages:</p>
<pre><code class="language-bash"># Production dependencies
pnpm add drizzle-orm @tauri-apps/plugin-sql

# Development dependencies
pnpm add -D drizzle-kit
</code></pre>
<p>Then add the Tauri plugin to your Rust dependencies in <code>src-tauri/Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
tauri-plugin-sql = { version = "2", features = ["sqlite"] }
</code></pre>
<h2>Step 2: Configure Tauri Permissions</h2>
<p>Tauri 2.0 requires explicit permission grants. Add SQL permissions to
<code>src-tauri/capabilities/default.json</code>:</p>
<pre><code class="language-json">{
  "$schema": "../gen/schemas/desktop-schema.json",
  "identifier": "default",
  "description": "Capability for the main window",
  "windows": ["main"],
  "permissions": [
    "core:default",
    "sql:default",
    "sql:allow-load",
    "sql:allow-execute",
    "sql:allow-select",
    "sql:allow-close"
  ]
}
</code></pre>
<p>Without these permissions, you'll get "not allowed" errors when trying to access
the database.</p>
<h2>Step 3: Define Your Schema</h2>
<p>Create your Drizzle schema at <code>app/db/schema.ts</code>:</p>
<pre><code class="language-typescript">import { sqliteTable, text, integer } from "drizzle-orm/sqlite-core";

export const vaults = sqliteTable("vaults", {
  id: integer("id").primaryKey({ autoIncrement: true }),
  name: text("name").notNull().unique(),
});
</code></pre>
<h2>Step 4: Set Up the SQLite Proxy</h2>
<p>Since we can't use standard SQLite drivers in Tauri, we use Drizzle's
<code>sqlite-proxy</code> adapter. Create <code>app/db/index.ts</code>:</p>
<pre><code class="language-typescript">import { drizzle } from "drizzle-orm/sqlite-proxy";
import Database from "@tauri-apps/plugin-sql";
import * as schema from "./schema";

export async function getDb() {
  return await Database.load("sqlite:keypears.db");
}

function isSelectQuery(sql: string): boolean {
  return sql.trim().toLowerCase().startsWith("select");
}

export const db = drizzle&#x3C;typeof schema>(
  async (sql, params, method) => {
    const sqlite = await getDb();
    let rows: any = [];

    if (isSelectQuery(sql)) {
      rows = await sqlite.select(sql, params).catch((e) => {
        console.error("SQL Error:", e);
        return [];
      });
    } else {
      rows = await sqlite.execute(sql, params).catch((e) => {
        console.error("SQL Error:", e);
        return [];
      });
      return { rows: [] };
    }

    rows = rows.map((row: any) => Object.values(row));
    const results = method === "all" ? rows : rows[0];
    await sqlite.close();
    return { rows: results };
  },
  { schema: schema, logger: true }
);
</code></pre>
<p>The proxy adapter translates Drizzle queries into calls to the Tauri SQL plugin.</p>
<h2>Step 5: Configure Migration Generation</h2>
<p>Create <code>drizzle.config.ts</code>:</p>
<pre><code class="language-typescript">import type { Config } from "drizzle-kit";

export default {
  schema: "./app/db/schema.ts",
  out: "./app/db/migrations",
  dialect: "sqlite",
} satisfies Config;
</code></pre>
<p>Add a script to <code>package.json</code>:</p>
<pre><code class="language-json">{
  "scripts": {
    "db:migrate": "drizzle-kit generate"
  }
}
</code></pre>
<h2>Step 6: Implement Migration Runner</h2>
<p>Here's the key part - implementing our own migration system. Create
<code>app/db/migrate.ts</code>:</p>
<pre><code class="language-typescript">import { getDb } from "./index";

// Dynamically import all SQL migration files
const migrationFiles = import.meta.glob&#x3C;string>("./migrations/*.sql", {
  query: "?raw",
  import: "default",
  eager: true,
});

// Create migrations tracking table
async function ensureMigrationsTable() {
  const sqlite = await getDb();
  await sqlite.execute(`
    CREATE TABLE IF NOT EXISTS __drizzle_migrations (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      hash TEXT NOT NULL UNIQUE,
      created_at INTEGER NOT NULL
    )
  `);
  await sqlite.close();
}

// Get list of applied migrations
async function getAppliedMigrations(): Promise&#x3C;string[]> {
  const sqlite = await getDb();
  const rows = await sqlite
    .select&#x3C;Array&#x3C;{ hash: string }>>(
      "SELECT hash FROM __drizzle_migrations ORDER BY id"
    )
    .catch(() => []);
  await sqlite.close();
  return rows.map((row) => row.hash);
}

// Record migration as applied
async function recordMigration(hash: string) {
  const sqlite = await getDb();
  const timestamp = Date.now();
  await sqlite.execute(
    "INSERT INTO __drizzle_migrations (hash, created_at) VALUES (?, ?)",
    [hash, timestamp]
  );
  await sqlite.close();
}

// Execute SQL file
async function executeSqlFile(sqlContent: string) {
  const sqlite = await getDb();
  const statements = sqlContent
    .split("--> statement-breakpoint")
    .map((s) => s.trim())
    .filter((s) => s.length > 0);

  for (const statement of statements) {
    await sqlite.execute(statement).catch((e) => {
      console.error("Migration error:", e);
      throw e;
    });
  }

  await sqlite.close();
}

export async function runMigrations() {
  console.log("Running database migrations...");

  try {
    await ensureMigrationsTable();
    const appliedMigrations = await getAppliedMigrations();

    const migrationPaths = Object.keys(migrationFiles).sort();

    const pendingMigrations = migrationPaths.filter((path) => {
      const filename = path.split("/").pop() || path;
      return !appliedMigrations.includes(filename);
    });

    if (pendingMigrations.length === 0) {
      console.log("All migrations already applied");
      return;
    }

    for (const path of pendingMigrations) {
      const filename = path.split("/").pop() || path;
      const migrationContent = migrationFiles[path];

      console.log(`Executing migration: ${filename}`);
      await executeSqlFile(migrationContent);
      await recordMigration(filename);
      console.log(`✓ Applied: ${filename}`);
    }

    console.log(`Successfully completed ${pendingMigrations.length} migration(s)`);
  } catch (error) {
    console.error("Migration failed:", error);
    throw error;
  }
}
</code></pre>
<p>This implements Drizzle's migration tracking pattern:</p>
<ul>
<li>Uses <code>__drizzle_migrations</code> table to track applied migrations</li>
<li>Only runs new migrations on subsequent app launches</li>
<li>Supports incremental migrations as your schema evolves</li>
</ul>
<h2>Step 7: Run Migrations on App Startup</h2>
<p>In your root component (<code>app/root.tsx</code>), use a clientLoader to run migrations
before rendering:</p>
<pre><code class="language-typescript">import { runMigrations } from "./db/migrate";

export async function clientLoader() {
  await runMigrations();
  return null;
}

export function HydrateFallback() {
  return (
    &#x3C;div className="flex min-h-screen items-center justify-center">
      &#x3C;h1>Migrating the database...&#x3C;/h1>
    &#x3C;/div>
  );
}
</code></pre>
<p>React Router will show the fallback while migrations run, ensuring the database
is ready before any component renders.</p>
<h2>Step 8: Create Model Functions</h2>
<p>With everything set up, create type-safe model functions at
<code>app/db/models/vault.ts</code>:</p>
<pre><code class="language-typescript">import { db } from "../index";
import { vaults } from "../schema";
import { eq, count } from "drizzle-orm";

export interface Vault {
  id: number;
  name: string;
}

export async function createVault(name: string): Promise&#x3C;Vault> {
  const result = await db.insert(vaults).values({ name }).returning();
  return result[0];
}

export async function getVault(id: number): Promise&#x3C;Vault | undefined> {
  const result = await db.select().from(vaults).where(eq(vaults.id, id));
  return result[0];
}

export async function getVaults(): Promise&#x3C;Vault[]> {
  return await db.select().from(vaults);
}

export async function countVaults(): Promise&#x3C;number> {
  const result = await db.select({ count: count() }).from(vaults);
  return result[0]?.count ?? 0;
}
</code></pre>
<h2>Usage Workflow</h2>
<h3>Development</h3>
<p>When you modify your schema:</p>
<pre><code class="language-bash"># 1. Update app/db/schema.ts
# 2. Generate new migration
pnpm run db:migrate

# 3. Restart app - migration runs automatically
</code></pre>
<p>During development, you can safely delete all migrations and regenerate them
from scratch. Just delete the database file and migration files, then
regenerate.</p>
<h3>Production</h3>
<p>Before releasing v1.0:</p>
<ol>
<li>Delete all development migrations</li>
<li>Generate one clean migration from your final schema</li>
<li>Commit this as your baseline</li>
</ol>
<p>After release, <strong>never delete migrations</strong> - only add new ones. Users will have
the old migrations applied, and new migrations build incrementally.</p>
<h2>Database File Location</h2>
<p>The Tauri SQL plugin creates the database in the app's data directory:</p>
<ul>
<li><strong>macOS</strong>: <code>~/Library/Application Support/{app-identifier}/keypears.db</code></li>
<li><strong>Linux</strong>: <code>~/.local/share/{app-identifier}/keypears.db</code></li>
<li><strong>Windows</strong>: <code>%APPDATA%\{app-identifier}\keypears.db</code></li>
</ul>
<h2>Troubleshooting</h2>
<p><strong>Permission errors</strong>: Make sure you've added all SQL permissions to
<code>capabilities/default.json</code></p>
<p><strong>Migration fails</strong>: Check browser console in the Tauri webview for detailed
error messages</p>
<p><strong>Type errors</strong>: Run <code>pnpm run typecheck</code> to catch issues before runtime</p>
<h2>Conclusion</h2>
<p>This setup gives us:</p>
<ul>
<li>✅ Type-safe database queries with Drizzle</li>
<li>✅ Proper migration tracking that works in production</li>
<li>✅ Pure TypeScript - no Rust code needed for basic operations</li>
<li>✅ Cross-platform compatibility (desktop &#x26; mobile)</li>
<li>✅ Incremental migrations as the schema evolves</li>
</ul>
<p>The combination of Drizzle's <code>sqlite-proxy</code> adapter with Tauri's SQL plugin
provides a robust foundation for local-first data storage. While we had to
implement our own migration runner, we followed Drizzle's patterns to ensure
compatibility and maintainability.</p>
<h2>Resources</h2>
<ul>
<li><a href="https://orm.drizzle.team/">Drizzle ORM</a></li>
<li><a href="https://v2.tauri.app/plugin/sql/">Tauri SQL Plugin</a></li>
<li><a href="https://v2.tauri.app/security/capabilities/">Tauri Capabilities</a></li>
</ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Introducing KeyPears: A New Approach to Password Management]]></title>
            <link>https://keypears.com/blog/2025-10-03-introducing-keypears</link>
            <guid isPermaLink="false">https://keypears.com/blog/2025-10-03-introducing-keypears</guid>
            <pubDate>Fri, 03 Oct 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[<p>We're excited to announce KeyPears, a new password manager designed for the
modern era of digital security and self-custody.</p>
<h2>Why KeyPears?</h2>
<p>Traditional password managers have served ...]]></description>
            <content:encoded><![CDATA[<p>We're excited to announce KeyPears, a new password manager designed for the
modern era of digital security and self-custody.</p>
<h2>Why KeyPears?</h2>
<p>Traditional password managers have served us well, but they come with
limitations. Most rely on centralized services, creating single points of
failure and raising questions about who truly controls your most sensitive data.
KeyPears takes a different approach.</p>
<h2>Local-First, Sync-Enabled</h2>
<p>KeyPears is built on a local-first architecture. Your secrets live on your
devices, encrypted with keys only you control. But unlike purely local
solutions, KeyPears solves the synchronization problem through a permissionless
marketplace of third-party service providers using an open protocol—similar to
how email works.</p>
<p>Anyone can run a KeyPears node. The protocol is open source. You maintain full
self-custody while enjoying seamless synchronization across all your devices.</p>
<h2>Built for Sharing</h2>
<p>Modern work requires secure secret sharing. KeyPears uses end-to-end encryption
with public/private key pairs for each user. When alice@example.com needs to
share a secret with bob@example2.com, they use Diffie-Hellman key exchange to
derive a shared secret that only they know. The architecture mirrors email, but
with cryptography-first design.</p>
<h2>More Than Passwords</h2>
<p>While we call it a password manager, KeyPears is designed to handle:</p>
<ul>
<li>Passwords</li>
<li>Cryptocurrency wallet keys</li>
<li>API keys</li>
<li>Environment variables</li>
<li>SSH keys</li>
<li>PGP keys</li>
</ul>
<p>For cryptocurrency users seeking self-custody and businesses that need secure
secret sharing without expensive enterprise subscriptions, KeyPears offers a
compelling alternative.</p>
<h2>What's Next</h2>
<p>KeyPears is in active development. We're building native applications for
Windows, macOS, Linux, Android, and iOS using Tauri. The project is Apache 2.0
licensed and open source.</p>
<p>This is just the beginning. We're excited to build KeyPears with the community
and create a new standard for secure, self-custodied secret management.</p>
<p>Stay tuned for more updates as we continue development.</p>]]></content:encoded>
        </item>
    </channel>
</rss>